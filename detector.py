import re
from typing import Dict, Any
import math


def _is_comment(line: str) -> bool:
    """Check if a line is a comment."""
    stripped = line.strip()
    return (stripped.startswith('#') or 
            stripped.startswith('//') or 
            stripped.startswith('/*') or 
            stripped.startswith('*'))


def _analyze_ai_patterns(code: str) -> Dict[str, float]:
    """Analyze code for AI-generated patterns."""
    features = {}
    lines = code.split('\n')
    non_empty_lines = [line for line in lines if line.strip()]
    
    # 1. AI Markers (strongest indicator)
    ai_markers = [
        "generated by", "chatgpt", "openai", "ai generated", "copilot", 
        "cursor ai", "gpt-", "claude", "anthropic", "assistant"
    ]
    has_ai_markers = any(marker in code.lower() for marker in ai_markers)
    features['has_ai_markers'] = 1.0 if has_ai_markers else 0.0
    
    # 2. Comment patterns
    comment_lines = [line for line in lines if _is_comment(line)]
    features['comment_density'] = len(comment_lines) / max(len(lines), 1)
    
    # Overly descriptive comments (AI pattern)
    descriptive_comments = sum(1 for line in comment_lines 
                              if len(line.strip()) > 80 and 
                              any(word in line.lower() for word in ['function', 'method', 'parameter', 'return', 'args', 'raises']))
    features['descriptive_comment_ratio'] = descriptive_comments / max(len(comment_lines), 1)
    
    # 3. Docstring patterns (AI loves detailed docstrings)
    docstrings = re.findall(r'"""[\s\S]*?"""|\'\'\'[\s\S]*?\'\'\'', code)
    features['docstring_count'] = len(docstrings)
    
    # Template-style docstrings (Args:, Returns:, Raises:)
    template_keywords = ['Args:', 'Returns:', 'Raises:', 'Examples:', 'Parameters:', 'Note:']
    template_docstrings = sum(1 for ds in docstrings if any(kw in ds for kw in template_keywords))
    features['template_docstring_ratio'] = template_docstrings / max(len(docstrings), 1)
    
    # 4. Naming patterns
    identifiers = re.findall(r'\b[a-zA-Z_][a-zA-Z0-9_]*\b', code)
    features['identifier_count'] = len(identifiers)
    
    if identifiers:
        # Generic names (AI loves these)
        generic_names = ['data', 'result', 'temp', 'value', 'item', 'element', 
                        'obj', 'var', 'output', 'input', 'param', 'args']
        generic_count = sum(1 for id in identifiers 
                           if id.lower() in generic_names or 
                           re.match(r'(data|result|temp|value|item)\d+', id.lower()))
        features['generic_name_ratio'] = generic_count / len(identifiers)
        
        # Overly long names (AI pattern)
        long_names = sum(1 for id in identifiers if len(id) > 25)
        features['long_name_ratio'] = long_names / len(identifiers)
        
        # Single character names (human pattern)
        single_char = sum(1 for id in identifiers if len(id) == 1 and id.isalpha())
        features['single_char_ratio'] = single_char / len(identifiers)
    else:
        features['generic_name_ratio'] = 0.0
        features['long_name_ratio'] = 0.0
        features['single_char_ratio'] = 0.0
    
    # 5. Code structure patterns
    # Function count
    functions = len(re.findall(r'\bdef\s+\w+|\bfunction\s+\w+|\bpublic\s+\w+\s+\w+', code))
    features['function_count'] = functions
    
    # Comments before functions (AI pattern)
    func_pattern = r'^\s*def\s+\w+|\bfunction\s+\w+|\bpublic\s+\w+\s+\w+'
    func_lines = [i for i, line in enumerate(lines) if re.search(func_pattern, line)]
    if func_lines:
        comments_before_funcs = sum(1 for i in func_lines 
                                   if i > 0 and _is_comment(lines[i-1]))
        features['comment_before_func_ratio'] = comments_before_funcs / len(func_lines)
    else:
        features['comment_before_func_ratio'] = 0.0
    
    # 6. Style consistency (AI is very consistent)
    if non_empty_lines:
        # Indentation consistency
        indents = [len(line) - len(line.lstrip()) for line in non_empty_lines]
        indent_variance = sum((i - sum(indents)/len(indents))**2 for i in indents) / len(indents)
        features['indent_consistency'] = 1.0 / (1.0 + indent_variance / 10.0)
        
        # Line length consistency
        lengths = [len(line) for line in non_empty_lines]
        length_variance = sum((l - sum(lengths)/len(lengths))**2 for l in lengths) / len(lengths)
        features['line_length_consistency'] = 1.0 / (1.0 + length_variance / 100.0)
    else:
        features['indent_consistency'] = 0.0
        features['line_length_consistency'] = 0.0
    
    # 7. Error handling (AI is comprehensive)
    try_blocks = len(re.findall(r'\btry\s*:', code))
    except_blocks = len(re.findall(r'\bexcept\b', code))
    if try_blocks > 0:
        features['error_handling_ratio'] = except_blocks / try_blocks
    else:
        features['error_handling_ratio'] = 0.0
    
    # 8. Repetition patterns
    line_freq = {}
    for line in non_empty_lines:
        line_freq[line] = line_freq.get(line, 0) + 1
    if line_freq:
        max_repetition = max(line_freq.values())
        features['repetition_ratio'] = (max_repetition - 1) / max(len(non_empty_lines) - 1, 1)
    else:
        features['repetition_ratio'] = 0.0
    
    return features


def analyze_code(code: str, language: str = 'auto') -> Dict[str, Any]:
    """
    Improved AI code detection with simplified and more effective scoring.
    
    Args:
        code: The source code to analyze
        language: Programming language (default: 'auto')
    
    Returns:
        Dictionary containing label, score, features, and explanation
    """
    # Extract features
    features = _analyze_ai_patterns(code)
    
    # ==================== Simplified Scoring Algorithm ====================
    score = 0.0
    
    # Strong indicators (high weight)
    if features['has_ai_markers']:
        score += 40.0  # Very strong indicator
    
    # Comment patterns
    if features['descriptive_comment_ratio'] > 0.3:
        score += 20.0
    elif features['descriptive_comment_ratio'] > 0.1:
        score += 10.0
    
    if features['comment_density'] > 0.3:
        score += 15.0
    elif features['comment_density'] > 0.15:
        score += 8.0
    
    # Docstring patterns
    if features['template_docstring_ratio'] > 0.5:
        score += 25.0
    elif features['template_docstring_ratio'] > 0.2:
        score += 15.0
    
    if features['docstring_count'] > 2:
        score += 10.0
    
    # Naming patterns
    if features['generic_name_ratio'] > 0.4:
        score += 20.0
    elif features['generic_name_ratio'] > 0.2:
        score += 10.0
    
    if features['long_name_ratio'] > 0.1:
        score += 15.0
    
    # Human patterns (reduce score)
    if features['single_char_ratio'] > 0.3:
        score -= 15.0  # Humans use short names
    
    # Structure patterns
    if features['comment_before_func_ratio'] > 0.8:
        score += 15.0
    elif features['comment_before_func_ratio'] < 0.2:
        score -= 10.0  # Humans don't always comment functions
    
    # Style consistency
    if features['indent_consistency'] > 0.9:
        score += 15.0
    elif features['indent_consistency'] < 0.5:
        score -= 10.0
    
    if features['line_length_consistency'] > 0.8:
        score += 10.0
    
    # Error handling
    if features['error_handling_ratio'] > 0.8:
        score += 10.0
    
    # Repetition
    if features['repetition_ratio'] > 0.3:
        score += 15.0
    elif features['repetition_ratio'] > 0.1:
        score += 8.0
    
    # Normalize score
    score = max(0.0, min(100.0, score))
    
    # ==================== Classification ====================
    if score >= 70:
        label = "AI-generated"
    elif score <= 30:
        label = "Human-written"
    else:
        label = "Uncertain"
    
    # ==================== Explanation ====================
    explanation = []
    
    if features['has_ai_markers']:
        explanation.append("Found explicit AI attribution markers in code or comments.")
    
    if features['descriptive_comment_ratio'] > 0.3:
        explanation.append("High ratio of overly descriptive comments typical of AI-generated code.")
    
    if features['template_docstring_ratio'] > 0.5:
        explanation.append("Template-style docstrings with Args/Returns/Raises format (AI pattern).")
    
    if features['generic_name_ratio'] > 0.4:
        explanation.append("High usage of generic variable names (data, result, temp, etc.).")
    
    if features['long_name_ratio'] > 0.1:
        explanation.append("Unusually long descriptive names detected (AI pattern).")
    
    if features['comment_before_func_ratio'] > 0.8:
        explanation.append("Almost every function has a comment above it (AI tendency).")
    
    if features['indent_consistency'] > 0.9:
        explanation.append("Perfect indentation consistency suggests automated generation.")
    
    if features['repetition_ratio'] > 0.3:
        explanation.append("Significant code repetition patterns detected.")
    
    if features['error_handling_ratio'] > 0.8:
        explanation.append("Comprehensive error handling in every try block (common in AI code).")
    
    # Human patterns
    if features['single_char_ratio'] > 0.3:
        explanation.append("High usage of single-character variable names suggests human coding style.")
    
    if features['comment_before_func_ratio'] < 0.2:
        explanation.append("Few functions have comments above them (human pattern).")
    
    if features['indent_consistency'] < 0.5:
        explanation.append("Inconsistent indentation suggests human authorship.")
    
    if not explanation:
        explanation.append("Mixed signals detected; classification is uncertain.")
    
    # Compile features for display
    display_features = {
        "lines": len(code.splitlines()),
        "characters": len(code),
        "comments": int(features['comment_density'] * len(code.splitlines())),
        "comment_ratio": round(features['comment_density'], 3),
        "has_ai_markers": bool(features['has_ai_markers']),
        "descriptive_comments": round(features['descriptive_comment_ratio'], 3),
        "template_docstrings": round(features['template_docstring_ratio'], 3),
        "generic_names": round(features['generic_name_ratio'], 3),
        "long_names": round(features['long_name_ratio'], 3),
        "single_char_names": round(features['single_char_ratio'], 3),
        "comment_before_func": round(features['comment_before_func_ratio'], 3),
        "indent_consistency": round(features['indent_consistency'], 3),
        "line_length_consistency": round(features['line_length_consistency'], 3),
        "error_handling": round(features['error_handling_ratio'], 3),
        "repetition": round(features['repetition_ratio'], 3),
        "language": language,
    }
    
    return {
        "label": label,
        "score": round(score, 1),
        "features": display_features,
        "explanation": explanation,
    }


# Backward compatibility
def analyze_code_simple(code: str) -> str:
    """Simple analysis returning just the label."""
    result = analyze_code(code)
    return result['label'] 